---
title: 《快手万亿级别Kafka集群应用实践与技术演进之路》观后心得
date: 2019-12-26 15:08:09
categories: 架构随笔录
tags: [架构,演讲]
toc: true
comments: true
---

> 本文用于记录观看快手万亿级别Kafka集群应用实践与技术演进之路演讲后的心得，从中确实学到了很多，快手作为kafka的重度使用者，对kafka集群从不同角度优化，其中发现问题，解决问题的思路都值得学习

以下这张图是本次演讲的内容，分章节阐述具体内容
![](https://ae01.alicdn.com/kf/Hb4200382b3f448eeb7ebbda8d380768cP.jpg)


# 平滑扩容
kafka集群节点扩容时，要做副本迁移，但kafka是从副本最开始的offset同步的，并且消息是在不断写入的，那么就要去同步的速度要大于写入的速度，才有可能同步完，要么就会产生以下问题
## 磁盘读取
从最开始的offset开始迁移，就极有可能是在磁盘上，而不是在pageCache中，迁移过程将加大磁盘的负载，影响生产者的写入效率，造成不稳定

同时kafka有消息过期机制，假设同步完成后，消息过期了，就白同步了。而在大型集群中，一次同步动辄几个小时都是有可能的

## 解决方式
对最早的offset同步产生质疑，是否有可能从最新的offset开始同步，答案是肯定的，但是这样做会有消费者丢失数据的情况。
假设以下情形，消费者拉取消息offset为5，高水位线为8，LEO为10，此时集群扩容，新副本从10开始同步，那么新副本成为leader后，就丢失了6-9的数据

解决这个问题也不难，快手的解决方案是同步一段时间，等所有消费者都已经消费。
我个人的观点是从消费者已提交的位置开始同步，保险起见可以再往前一部分offset

# Mirror集群
MirrorMarker是用于同步多个kafka集群的工具，但它有很多缺点，不足以大规模应用
1. 无法同步消费者offset
2. 缺乏监控
3. topic是静态配置的，增加topic需要重启MirrorMarker
4. 只支持一个集群到另一个集群的同步，无法同步多个集群


# 可用性改造

# 资源隔离

# cache改造
cache改造是我很感兴趣的一个部分，原来pageCache有很多稳定性问题，导致缓存命中率降低
1. follower副本同步时也会走pageCache，但如果是在扩容时，就会从磁盘读取历史消息，导致pageCache被历史消息占用，这样消费者来拉取消息时就会走磁盘
2. 线上环境消息积压是极有可能的情况，那么积压的消息大概率是在磁盘中，此时消费者拉取消息就会将历史消息加载pageCache中，生产者写入消息时pageCache的空间就会减少，造成写磁盘，会加大磁盘负载

## 解决方式








